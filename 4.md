**笔记：**

**环境安装**

为了使用 XTuner，需进行以下步骤进行环境安装：

1. **InternStudio 平台操作**：
   - 从本地克隆一个已包含 PyTorch 2.0.1（搭配 Python 3.10, CUDA 11.7, cuDNN 8.5.0）的环境：`studio-conda xtuner0.1.17`

# 2.2 前期准备

## 2.2.1 数据集准备

为了使模型在被询问身份时能够准确地以我们期望的方式作出回应，关键在于在微调数据集中大量包含此类引导信息。以下是具体步骤：

### 创建文件结构
首先，创建一个文件夹来组织本次训练所需的全部文件，确保数据集、模型和相关脚本集中管理。

### 生成数据集
在创建的 `data` 目录下新建 `generate_data.py` 文件，并将以下代码粘贴至其中。通过调整参数 `n` 的值（增大可增强模型对特定身份的认知），运行此脚本以生成所需数据集。

### 修改与运行
根据需求调整 `n` 值后，执行 `generate_data.py` 脚本，生成经过优化的身份识别数据集。

## 2.2.2 模型准备

在数据集准备完毕后，下一步是选用适合微调的模型。考虑到课程环境的显存限制，我们将采用 InternLM 最新发布的轻量级模型 `InterLM2-Chat-1.8B` 进行演示。

### InternStudio 用户操作
对于在 InternStudio 平台上工作的用户，无需通过 OpenXLab 或 Modelscope 下载模型。只需执行以下代码，即可自动创建文件夹并复制所有必要的模型文件至指定位置，实现一键式模型准备。

```python
# 代码示例：一键创建文件夹并复制模型文件
# 注意：此处仅为示意，实际代码请替换为实际操作指令

import os
from shutil import copytree

model_name = 'InterLM2-Chat-1.8B'
model_dir = f'/path/to/{model_name}'

if not os.path.exists(model_dir):
    os.makedirs(model_dir)

# 假设模型文件位于 '/path/to/downloaded_model_files'
source_dir = '/path/to/downloaded_model_files'
copytree(source_dir, model_dir)
**验证与后续准备**
![image](https://github.com/ccly1996/InternLMClass/assets/39228103/20397c03-724b-427b-a4b4-635acad91f82)

![image](https://github.com/ccly1996/InternLMClass/assets/39228103/529a5dd5-fe3f-445f-b634-d5b87070faab)

![image](https://github.com/ccly1996/InternLMClass/assets/39228103/49321768-e138-4c78-af36-a0fca39857e6)
![image](https://github.com/ccly1996/InternLMClass/assets/39228103/d8f20e2e-5fd9-42f8-956b-114b229e0c26)
