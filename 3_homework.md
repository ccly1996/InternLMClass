## 2.在 InternLM Studio 上部署茴香豆技术助手
笔记：# RAG 技术概述与茴香豆应用

RAG（Retrieval Augmented Generation）技术是一种结合检索和生成的方法，旨在提高大型语言模型（LLMs）在知识密集型任务中的性能。通过检索与用户输入相关的信息片段，并结合外部知识库，RAG技术能够生成更准确、更丰富的回答。这对于解决LLMs在处理复杂问题时可能遇到的挑战，如幻觉、知识过时和缺乏透明、可追溯的推理过程等问题，具有重要意义。

## 茴香豆应用

茴香豆是一款基于RAG技术构建的群聊助手，它能够快速、高效地搭建起针对特定知识领域的助手。茴香豆利用RAG技术，实现了非参数化的知识更新，即使在没有额外训练的情况下，也能掌握新领域的知识，从而提供准确的回答、降低推理成本，并实现外部记忆。

### 环境配置

在Intern Studio服务器上部署茴香豆，首先需要配置开发机系统，选择适合的镜像和资源配置。接着，复制运行InternLM的基础环境，并激活相应的Python虚拟环境。此外，还需下载并安装所需的模型文件和依赖包。

### 使用茴香豆搭建RAG助手

#### 修改配置文件

配置文件中需要指定模型路径，包括用于向量数据库和词嵌入的模型、检索的重排序模型，以及大模型的路径。

#### 创建知识库

通过下载和提取Huixiangdou的语料，创建向量数据库，茴香豆能够将输入问题与接受和拒绝问题列表中的问题进行相似性比较，从而精确判断提问的相关性，并生成准确的回答。

#### 运行茴香豆知识助手

运行茴香豆后，可以测试其效果。RAG技术的优势在于，即使没有对基础模型进行额外训练，也能根据提供的知识库生成准确的答案。

RAG技术结合茴香豆应用，为构建知识密集型问答系统提供了一种有效的解决方案。通过非参数化的知识更新和外部记忆，茴香豆能够快速适应新的知识领域，提供准确、丰富的回答，极大地提高了群聊助手的实用性和效率。
![image](https://github.com/ccly1996/InternLMClass/assets/39228103/50f124f2-a669-4a7c-b180-3a75962b706f)
